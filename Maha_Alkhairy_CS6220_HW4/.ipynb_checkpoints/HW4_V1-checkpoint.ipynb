{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## CS6220 - HW4 - Maha Alkhairy\n",
    "### Clustering and evaluation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Written part: \n",
    "#### for more detail look at the scanned pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: \n",
    "a. The clusters given their points: \n",
    "* Cluster 1: {[0, 1], [1, 2], [2, 3], [3, 4]} \n",
    "* Cluster 2: {[5, 2], [6, 1], [7, 2], [6, 3]}\n",
    "\n",
    "b. Points which are density connected: \n",
    "* [0, 1], [1, 2], [2, 3] and [3, 4] are density connected\n",
    "* [5, 2], [6, 1], [7, 2] and [6, 3] are density connected   \n",
    "c. Points considered as noise are: [0, 6], [0, 7] and [10, 3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ******  plotting the written part to make sense of data ****\n",
    "data_DBSCAN = np.array([[0, 1], \n",
    "                        [5, 2], \n",
    "                        [2, 3], \n",
    "                        [6, 1], \n",
    "                        [10, 2],\n",
    "                        [0, 6], \n",
    "                        [3, 4], \n",
    "                        [6, 3], \n",
    "                        [0, 7], \n",
    "                        [7, 2], \n",
    "                        [1, 2]])\n",
    "\n",
    "# print(data_DBSCAN)\n",
    "\n",
    "\n",
    "df_2 = DataFrame(data_DBSCAN, columns = ['x1', 'x2'])\n",
    "df_2.plot(kind='scatter', x = 'x1', y = 'x2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: \n",
    "C<sub>1</sub> = {(5, 6), (8, 7), (7, 3)} <br/>\n",
    "C<sub>2</sub> = {(6, 5), (4, 5), (9, 2), (3, 5), (8, 4)}\n",
    "\n",
    "a. mean vectors: \n",
    " * m1 = [6.66666, 5.33333] (mean of first cluster (1 × 2))\n",
    " * m2 = [6, 4.2]            (mean of second cluster (1 × 2)) \n",
    " \n",
    "b. total mean vector: \n",
    "* m = [6.25, 4.625]       (mean of all points (1 × 2))  \n",
    "\n",
    "\n",
    "c. Scatter matrices of the clusters \n",
    "* S<sub>1</sub> = [[4.6666, 0.333333], [0.33333, 8.66666]]   (scatter matrix of cluster 1 (2 × 2)) \n",
    "* S<sub>2</sub> = [[26, -11], [-11, 6.8]]   (scatter matrix of cluster 2 (2 × 2))  \n",
    " \n",
    "d. Within cluster scatter matrix (2 × 2)\n",
    "* S<sub>w</sub> = S<sub>1</sub> + S<sub>2</sub> = [[30.6666, -10.6666], [-10.6666, 15.46666]]\n",
    "\n",
    "\n",
    "e. Between cluster scatter matrix (2 × 2)\n",
    "* S<sub>b</sub> = (m1 - m).T × (m1 - m) = [[0.83333, 1.4166666], [1.4166666, 2.40833333]]\n",
    "\n",
    "f. evaluation: based on the scattering criteria, this clustering is not good. \n",
    "* tr(S<sub>w</sub>)  = 30.6666 + 15.46666  = 46.1333 (want low)\n",
    "* tr(S<sub>b</sub>)  = 0.83333 + 2.40833333 = 3.2416666 (want high)\n",
    "* (tr(S<sub>b</sub>)  / tr(S<sub>w</sub>)) = 0.070267 (want high)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ******  plotting the written part to make sense of data ****\n",
    "cluster1 = [[5, 6], [8, 7], [7, 3]]\n",
    "cluster2 = [[6, 5], [4, 5], [9, 2], [3, 5], [8, 4]]\n",
    "\n",
    "# all_data = list(cluster1)\n",
    "# all_data.extend(cluster2)\n",
    "\n",
    "# cluster1_matrix = np.array(cluster1)\n",
    "# cluster2_matrix = np.array(cluster2)\n",
    "\n",
    "# all_data_matrix = np.array(all_data)\n",
    "\n",
    "\n",
    "df = DataFrame(np.array(cluster1), columns = ['x1', 'x2'])\n",
    "c1 = df.plot(kind='scatter', x = 'x1', y = 'x2')\n",
    "# plt.show()\n",
    "\n",
    "df1 = DataFrame(np.array(cluster2), columns = ['x1', 'x2'])\n",
    "df1.plot(kind='scatter', x = 'x1', y = 'x2', c = ['red'], ax = c1)\n",
    "plt.show()\n",
    "    \n",
    "# m1 = np.mean(cluster1_matrix, axis=0)\n",
    "# m2 = np.mean(cluster2_matrix, axis=0)\n",
    "# m = np.mean(all_data_matrix, axis=0)\n",
    "\n",
    "# C1_m1 = cluster1_matrix - m1\n",
    "# C2_m2 = cluster2_matrix - m2\n",
    "\n",
    "# S1 = np.dot(C1_m1.T, C1_m1)\n",
    "# S2 = np.dot(C2_m2.T, C2_m2)\n",
    "# S_W = S1 + S2 \n",
    "\n",
    "# m_1 = np.array([(m1 - m)])\n",
    "# m_2 = np.array([(m2 - m)])\n",
    "# S_B = np.dot(m_1.T, m_1) * 3 + np.dot(m_2.T, m_2) * 5\n",
    "# np.shape(S_B)\n",
    "# print(S_B.trace()/ S_W.trace())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming part: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of different types of clustering \n",
    "\"\"\"\n",
    "import random\n",
    "import sklearn \n",
    "import numpy as np \n",
    "import scipy.io \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import normalized_mutual_info_score, silhouette_score, calinski_harabaz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = np.loadtxt(\"datasets/datasets/dataset1.txt\",\n",
    "                    dtype = {'names': ('x1', 'x2', 'label'), 'formats': (float, float, int)},\n",
    "                    delimiter=\"\\t\")\n",
    "data2 = np.loadtxt(\"datasets/datasets/dataset2.txt\",\n",
    "                   dtype = {'names': ('x1', 'x2', 'label'), 'formats': (float, float, int)}, \n",
    "                   delimiter=\"\\t\")\n",
    "data3 = np.loadtxt(\"datasets/datasets/dataset3.txt\",\n",
    "                   dtype = {'names': ('x1', 'x2', 'label'), 'formats': (float, float, int)}, \n",
    "                   delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_io_matrix(d): \n",
    "    \"\"\"\n",
    "    formats the input data in a matrix format (n × d) where d is the number of dimentions and n is the number of data points \n",
    "    formats the label data in a matrix format (n × 1) where n is the number of data points \n",
    "    \"\"\"\n",
    "    matrix_input = [[x1, x2] for x1, x2, l in d]\n",
    "    matrix_labels = [l for x1, x2, l in d]\n",
    "    \n",
    "    return (np.array(matrix_input), np.array(matrix_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 2)\n"
     ]
    }
   ],
   "source": [
    "### number of clusters = 3\n",
    "data1_matrix, data1_labels = create_io_matrix(data1)\n",
    "# print(len(data1))\n",
    "print(np.shape(data1_matrix))\n",
    "# print(np.shape(data1_labels))\n",
    "# print(data1_labels)\n",
    "### number of cluster = 3\n",
    "data2_matrix, data2_labels = create_io_matrix(data2)\n",
    "# print(len(data2))\n",
    "# print(np.shape(data2_matrix))\n",
    "# print(np.shape(data2_labels))\n",
    "# print(data2_labels)\n",
    "### number of clusters = 2\n",
    "data3_matrix, data3_labels = create_io_matrix(data3)\n",
    "# print(len(data3))\n",
    "# print(np.shape(data3_matrix))\n",
    "# print(np.shape(data3_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############# initial data visualization \n",
    "\n",
    "df_1 = DataFrame(data1_matrix, columns = ['x1', 'x2'])\n",
    "df_1.plot(kind='scatter', x = 'x1', y = 'x2')\n",
    "\n",
    "print(\"=================== data 1 ======================\")\n",
    "plt.show()\n",
    "\n",
    "df_2 = DataFrame(data2_matrix, columns = ['x1', 'x2'])\n",
    "df_2.plot(kind='scatter', x = 'x1', y = 'x2')\n",
    "\n",
    "print(\"===================== data 2 ===================\")\n",
    "plt.show()\n",
    "\n",
    "df_3 = DataFrame(data3_matrix, columns = ['x1', 'x2'])\n",
    "df_3.plot(kind='scatter', x = 'x1', y = 'x2')\n",
    "\n",
    "print(\"================= data 3 ==================\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on the plotting of the points above, I would predict that k-means would be the best algorithm to get the clusters is k-means with 3 clusters \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### used sudo code from wikipedia\n",
    "\n",
    "DBSCAN(D, eps, MinPts) {\n",
    "   C = 0\n",
    "   for each point P in dataset D {\n",
    "      if P is visited\n",
    "         continue next point\n",
    "      mark P as visited\n",
    "      NeighborPts = regionQuery(P, eps)\n",
    "      if sizeof(NeighborPts) < MinPts\n",
    "         mark P as NOISE\n",
    "      else {\n",
    "         C = next cluster\n",
    "         expandCluster(P, NeighborPts, C, eps, MinPts)\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "expandCluster(P, NeighborPts, C, eps, MinPts) {\n",
    "   add P to cluster C\n",
    "   for each point P' in NeighborPts { \n",
    "      if P' is not visited {\n",
    "         mark P' as visited\n",
    "         NeighborPts' = regionQuery(P', eps)\n",
    "         if sizeof(NeighborPts') >= MinPts\n",
    "            NeighborPts = NeighborPts joined with NeighborPts'\n",
    "      }\n",
    "      if P' is not yet member of any cluster\n",
    "         add P' to cluster C\n",
    "   }\n",
    "}\n",
    "\n",
    "regionQuery(P, eps)\n",
    "   return all points within P's eps-neighborhood (including P)\n",
    "\"\"\"\n",
    "\n",
    "### DBSCAN Algorithm: \n",
    "def DBSCAN(eps, min_points, input_matrix): \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    visited = []\n",
    "    noise = []\n",
    "    clusters = []\n",
    "    \n",
    "    print(\"DBSCAN ....\")\n",
    "  \n",
    "    for p in input_matrix:\n",
    "        if not(list(p) in visited):\n",
    "            visited.append(list(p))\n",
    "            neighbors = region_query(p, eps, input_matrix) \n",
    "            if len(neighbors) < min_points: \n",
    "#                 print(\"found noise\") \n",
    "                noise.append(p)\n",
    "            else: \n",
    "                c = []\n",
    "#                 print(\"found a new cluster\") \n",
    "                cluster_expanded = expand_cluster(p, neighbors, c, eps, min_points, visited, clusters, input_matrix)\n",
    "#                 print(\"left expand_cluster\")\n",
    "                clusters.append(cluster_expanded)\n",
    "    return (clusters, noise)\n",
    "            \n",
    "\n",
    "def expand_cluster(p, neighbors, c, eps, min_points, visited, clusters, input_matrix): \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "#     print(\"in expand cluster\")\n",
    "#     print(len(neighbors))\n",
    "    c.append(list(p))\n",
    "    for q in neighbors: \n",
    "        if list(q) not in visited: \n",
    "            visited.append(list(q))\n",
    "            new_neighbors = region_query(q, eps, input_matrix)\n",
    "            if len(new_neighbors) >= min_points: \n",
    "                neighbors.extend(new_neighbors)\n",
    "        else: \n",
    "            if not member_cluster(q, clusters):\n",
    "                c.append(q)\n",
    "    return c\n",
    "            \n",
    "def member_cluster(q, clusters):\n",
    "    for c in clusters: \n",
    "        if list(q) in c:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def region_query(p, eps, input_matrix): \n",
    "    \"\"\"\n",
    "    :return: all points within P's eps-neighborhood (including P)\n",
    "    \"\"\"\n",
    "    eps_neighbors = [list(x) for x in input_matrix if (distance.euclidean(x, p) <= eps)]\n",
    "    return eps_neighbors\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN ....\n",
      "DBSCAN ....\n",
      "DBSCAN ....\n",
      "DBSCAN ....\n",
      "DBSCAN ....\n",
      "DBSCAN ....\n",
      "DBSCAN ....\n",
      "DBSCAN ....\n",
      "DBSCAN ....\n"
     ]
    }
   ],
   "source": [
    "clusters111, noise111 = DBSCAN(0.2, 2, data1_matrix)\n",
    "clusters112, noise112 = DBSCAN(0.2, 3, data1_matrix)\n",
    "clusters113, noise113 = DBSCAN(0.2, 4, data1_matrix)\n",
    "\n",
    "clusters121, noise121 = DBSCAN(0.3, 2, data1_matrix)\n",
    "clusters122, noise122 = DBSCAN(0.3, 3, data1_matrix)\n",
    "clusters123, noise123 = DBSCAN(0.3, 4, data1_matrix)\n",
    "\n",
    "\n",
    "clusters131, noise131 = DBSCAN(0.4, 2, data1_matrix)\n",
    "clusters132, noise132 = DBSCAN(0.4, 3, data1_matrix)\n",
    "clusters133, noise133 = DBSCAN(0.4, 4, data1_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters, noise = DBSCAN(0.8, 6, data2_matrix)\n",
    "clusters, noise = DBSCAN(0.8, 7, data2_matrix)\n",
    "clusters, noise = DBSCAN(0.8, 8, data2_matrix)\n",
    "\n",
    "clusters, noise = DBSCAN(0.85, 6, data2_matrix)\n",
    "clusters, noise = DBSCAN(0.85, 7, data2_matrix)\n",
    "clusters, noise = DBSCAN(0.85, 8, data2_matrix)\n",
    "\n",
    "clusters, noise = DBSCAN(0.9, 6, data2_matrix)\n",
    "clusters, noise = DBSCAN(0.9, 7, data2_matrix)\n",
    "clusters, noise = DBSCAN(0.9, 8, data2_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters, noise = DBSCAN(0.2, 5, data3_matrix)\n",
    "clusters, noise = DBSCAN(0.2, 6, data3_matrix)\n",
    "clusters, noise = DBSCAN(0.2, 7, data3_matrix)\n",
    "\n",
    "clusters, noise = DBSCAN(0.3, 5, data3_matrix)\n",
    "clusters, noise = DBSCAN(0.3, 6, data3_matrix)\n",
    "clusters, noise = DBSCAN(0.3, 7, data3_matrix)\n",
    "\n",
    "\n",
    "clusters, noise = DBSCAN(0.4, 5, data3_matrix)\n",
    "clusters, noise = DBSCAN(0.4, 6, data3_matrix)\n",
    "clusters, noise = DBSCAN(0.4, 7, data3_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotResultsDBSCAN(clusters, noise, colors, K):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    K = len(clusters)\n",
    "    df = DataFrame(np.array(clusters[0]), columns = ['x1', 'x2'])\n",
    "    c_0 =  df.plot(kind='scatter', x = 'x1', y = 'x2', color=colors[0])\n",
    " \n",
    "    c_k = None \n",
    "    for k in range(K-1):\n",
    "        k = k + 1\n",
    "        df = DataFrame(np.array(clusters[k]), columns = ['x1', 'x2'])\n",
    "        c_k =  df.plot(kind='scatter', x = 'x1', y = 'x2', color=colors[k], ax=c_0)\n",
    "        df = DataFrame(centroids, columns = ['x1', 'x2'])\n",
    "\n",
    "        df.plot(kind='scatter', x = 'x1', y = 'x2', color='black', s = 25, marker = 'x',  ax = c_k)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### K-means algorithm \n",
    "## * should preform multiple random initializations and keep the best \n",
    "## ---- not crash when initialization results in empty clusters\n",
    "\n",
    "def K_means_helper(K, input_matrix, initial_means = False): \n",
    "    \"\"\"\n",
    "    K: number of clusters \n",
    "    ...\n",
    "    \"\"\"\n",
    "    N, d = np.shape(input_matrix)\n",
    "    if not initial_means: \n",
    "        randomInts = [random.randint(1, N-1)  for i in range(K)]\n",
    "        cluster_means = [input_matrix[i] for i in randomInts]\n",
    "    else: \n",
    "        cluster_means = initial_means\n",
    "\n",
    "    i = 0 \n",
    "    ### should be till convergence \n",
    "    while i < 1000:\n",
    "        cluster_assignments = get_cluster_assignments(K, cluster_means, input_matrix)\n",
    "        previous_means = cluster_means\n",
    "        cluster_means = get_cluster_means(K, cluster_assignments, input_matrix)\n",
    "        return (cluster_assignments, cluster_means)\n",
    "        i += 1\n",
    "        \n",
    "def get_cluster_assignments(K, cluster_means, input_matrix): \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    N, d = np.shape(input_matrix)\n",
    "    print(N, d)\n",
    "    cluster_assignments = np.zeros((N, K))\n",
    "    ### the rows are one hot vectors which indicate whether the data point is in the cluster\n",
    "    \n",
    "    for i in range(N): \n",
    "        x_i = input_matrix[i]\n",
    "        distances = list(map(lambda m: np.linalg.norm((x_i - m), ord=2), cluster_means))\n",
    "        k = distances.index(min(distances))\n",
    "        cluster_assignments[i, k] = 1\n",
    "    return cluster_assignments\n",
    "        \n",
    "def get_cluster_means(K, cluster_assignments, input_matrix):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    N, d = np.shape(input_matrix)\n",
    "    new_means = [0 for i in range(K)]\n",
    "    \n",
    "    for k in range(K):\n",
    "        c = cluster_assignments[:, k]\n",
    "        den = np.sum(cluster_assignments, axis = 0)[0]\n",
    "#         print(den)\n",
    "        num = 0\n",
    "        for i in range(N): \n",
    "            if cluster_assignments[i, k] == 1: \n",
    "                num += input_matrix[i]\n",
    "        if num is 0: \n",
    "            new_means[k] = np.zeros(1, d)\n",
    "        else:\n",
    "            new_means[k] = num/den\n",
    "            \n",
    "    return new_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getClusteredData(input_matrix, cluster_assignments, k):\n",
    "#     print(K)\n",
    "    wanted = cluster_assignments[:, k]\n",
    "    \n",
    "    wanted_X = []\n",
    "   \n",
    "    for i in range(len(wanted)):\n",
    "        if cluster_assignments[i][k] == 1: \n",
    "            wanted_X.append(input_matrix[i])\n",
    "            \n",
    "    return wanted_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def check_results(cluster_assignments, input_matrix, ): \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotResults(input_matrix, cluster_assignments, centroids, K, colors):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    cluster_0  =  getClusteredData(input_matrix, cluster_assignments, 0)\n",
    "    df = DataFrame(cluster_0, columns = ['x1', 'x2'])\n",
    "    c_0 =  df.plot(kind='scatter', x = 'x1', y = 'x2', color=colors[0])\n",
    " \n",
    "    c_k = None \n",
    "    for k in range(K-1):\n",
    "        k = k + 1\n",
    "        cluster_k  =  getClusteredData(input_matrix, cluster_assignments, k)\n",
    "        df = DataFrame(cluster_k, columns = ['x1', 'x2'])\n",
    "        c_k =  df.plot(kind='scatter', x = 'x1', y = 'x2', color=colors[k], ax=c_0)\n",
    "        df = DataFrame(centroids, columns = ['x1', 'x2'])\n",
    "\n",
    "        df.plot(kind='scatter', x = 'x1', y = 'x2', color='black', s = 25, marker = 'x',  ax = c_k)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########### run k-means: \n",
    "\n",
    "def plot_k_means(data_matrix, K): \n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    cluster_assignments, cluster_means = K_means_helper(K, data_matrix)\n",
    "    print(cluster_means)\n",
    "    plotResults(data_matrix,\n",
    "                cluster_assignments, \n",
    "                cluster_means,\n",
    "                K, \n",
    "                [\"red\", \"blue\", \"green\", \"pink\", \"yellow\"])\n",
    "    \n",
    "    \n",
    "plot_k_means(data1_matrix, 2)\n",
    "plot_k_means(data2_matrix, 2)\n",
    "plot_k_means(data3_matrix, 2)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Expectation Maximization for gaussian mixture models \n",
    "## * should perform multiple restarts and accept initial values for the mean and covariance as input \n",
    "\n",
    "## initialize the the mean by sampling from a gaussian distribution centered on a random point in the data\n",
    "\n",
    "## initialize the variance along each dimension to a random fraction of the total variance in the data\n",
    "\n",
    "## \n",
    "\n",
    "def GMM(init_mean, init_variance): \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
